"""
APSæ™ºæ…§æ’äº§ç³»ç»Ÿ - å¹¶è¡Œå¤„ç†ç®—æ³•ï¼ˆç®—æ³•ç»†åˆ™å¢å¼ºç‰ˆï¼‰

å®ç°åŒå·¥å•åœ¨å¤šæœºå°çš„åŒæ­¥æ‰§è¡Œé€»è¾‘
æ ¸å¿ƒä¸šåŠ¡ï¼š
1. åŒä¸€å·¥å•çš„ä¸åŒæœºå°å¿…é¡»åŒæ—¶å¼€å§‹ã€åŒæ—¶ç»“æŸ
2. è€ƒè™‘æœºå°è½®ä¿æ—¶é—´è°ƒæ•´
3. å¤„ç†å–‚ä¸æœºèµ„æºå†²çªå¯¼è‡´çš„æ—¶é—´è°ƒæ•´
4. æ”¯æŒå›¾6ä¸­çš„å¤æ‚å¹¶è¡Œåˆ‡åˆ†åŸåˆ™
"""
from typing import List, Dict, Any, Optional
from datetime import datetime
from collections import defaultdict
from .base import AlgorithmBase, ProcessingStage, AlgorithmResult
import logging

logger = logging.getLogger(__name__)


class ParallelProcessing(AlgorithmBase):
    """å¹¶è¡Œå¤„ç†ç®—æ³• - ç®€åŒ–ç‰ˆï¼Œä¸“æ³¨äºåŒå·¥å•æœºå°åŒæ­¥"""
    
    def __init__(self):
        super().__init__(ProcessingStage.PARALLEL_PROCESSING)
        
    async def process(self, input_data: List[Dict[str, Any]], **kwargs) -> AlgorithmResult:
        """
        æ‰§è¡Œå¹¶è¡Œå¤„ç† - ç®€åŒ–ç‰ˆ
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        1. æŒ‰work_order_nråˆ†ç»„ï¼ˆç›¸åŒå·¥å•çš„ä¸åŒæœºå°ï¼‰
        2. æ¯ç»„å†…åŒæ­¥æ‰€æœ‰æœºå°çš„å¼€å§‹å’Œç»“æŸæ—¶é—´
        3. ç¡®ä¿åŒä¸€å·¥å•çš„æ‰€æœ‰æœºå°åŒæ—¶å¼€å§‹ã€åŒæ—¶ç»“æŸ
        
        Args:
            input_data: æ—¶é—´æ ¡æ­£åçš„å·¥å•æ•°æ®
            
        Returns:
            AlgorithmResult: å¹¶è¡Œå¤„ç†ç»“æœ
        """
        result = self.create_result()
        result.input_data = input_data
        result.metrics.processed_records = len(input_data)
        
        if not input_data:
            result.output_data = []
            return self.finalize_result(result)
        
        # æŒ‰å·¥å•å·åˆ†ç»„
        work_order_groups = self._group_by_work_order(input_data)
        
        synchronized_orders = []
        sync_groups_count = 0
        
        for work_order_nr, orders in work_order_groups.items():
            if len(orders) > 1:
                # å¤šå°æœºå°éœ€è¦åŒæ­¥
                sync_group = self._synchronize_machines(orders)
                synchronized_orders.extend(sync_group)
                sync_groups_count += 1
                logger.info(f"åŒæ­¥å·¥å•{work_order_nr}çš„{len(orders)}å°æœºå°")
            else:
                # å•å°æœºå°ï¼Œç›´æ¥æ·»åŠ 
                order = orders[0].copy()
                order['is_synchronized'] = False
                order['sync_reason'] = 'å•å°æœºå°ï¼Œæ— éœ€åŒæ­¥'
                synchronized_orders.append(order)
        
        result.output_data = synchronized_orders
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        result.metrics.custom_metrics = {
            'sync_groups_created': sync_groups_count,
            'total_machines_synchronized': sum(len(orders) for orders in work_order_groups.values() if len(orders) > 1),
            'sync_efficiency': sync_groups_count / len(work_order_groups) if work_order_groups else 0
        }
        
        logger.info(f"å¹¶è¡Œå¤„ç†å®Œæˆ: åˆ›å»º{sync_groups_count}ä¸ªåŒæ­¥ç»„ï¼Œå¤„ç†{len(synchronized_orders)}ä¸ªå·¥å•")
        return self.finalize_result(result)
    
    def _group_by_work_order(self, orders: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """
        æŒ‰å·¥å•å·åˆ†ç»„
        
        Args:
            orders: å·¥å•åˆ—è¡¨
            
        Returns:
            Dict: {å·¥å•å·: [å·¥å•åˆ—è¡¨]}
        """
        groups = defaultdict(list)
        
        for order in orders:
            work_order_nr = order.get('work_order_nr', 'UNKNOWN')
            groups[work_order_nr].append(order)
        
        return dict(groups)
    
    def _synchronize_machines(self, orders: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        åŒæ­¥ä¸€ä¸ªå·¥å•ä¸‹æ‰€æœ‰æœºå°çš„æ—¶é—´ - æŒ‰ç…§ç®—æ³•ç»†åˆ™å¢å¼º
        
        ç®—æ³•ç»†åˆ™è¦æ±‚ï¼š
        1. åŒä¸€å·¥å•ä¸‹æ‰€æœ‰æœºå°å¿…é¡»åŒæ—¶å¼€å§‹ã€åŒæ—¶ç»“æŸ
        2. è€ƒè™‘æœºå°è½®ä¿æ—¶é—´ï¼ˆå·åŒ…æœº1å¯¹å·åŒ…æœº2ç»“æŸé˜¶æ®µä¸ºè½®ä¿ï¼‰
        3. å·åŒ…æ ¡æ­£çš„å¼€å§‹æ—¶é—´ï¼Œéœ€è¦è€ƒè™‘å–‚ä¸æœºä¹‹å‰çš„ä»»åŠ¡å·²ç»ç»“æŸ
        4. å¯ä»¥è®¤ä¸º3ä¸ªå·åŒ…æœºå°çš„å¼€å§‹æ—¶é—´ä¸ºå·åŒ…æœº3çš„å¼€å§‹æ—¶é—´ï¼Œç»™1ï¼Œ3è°ƒæ•´åçš„æ—¶é—´
        
        Args:
            orders: åŒä¸€å·¥å•çš„æœºå°è®¢å•åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: åŒæ­¥åçš„å·¥å•åˆ—è¡¨
        """
        if not orders:
            return []
        
        work_order_nr = orders[0].get('work_order_nr', 'UNKNOWN')
        logger.info(f"ğŸ”„ å¼€å§‹åŒæ­¥å·¥å•{work_order_nr}çš„{len(orders)}å°æœºå°")
        
        # æ”¶é›†æ—¶é—´ä¿¡æ¯å¹¶è½¬æ¢æ ¼å¼
        processed_orders = []
        for order in orders:
            processed_order = order.copy()
            
            start = order.get('planned_start')
            end = order.get('planned_end')
            
            if isinstance(start, str):
                start = datetime.fromisoformat(start.replace('Z', '+00:00'))
                processed_order['planned_start'] = start
            if isinstance(end, str):
                end = datetime.fromisoformat(end.replace('Z', '+00:00'))
                processed_order['planned_end'] = end
                
            processed_orders.append(processed_order)
        
        # è·å–æœ‰æ•ˆçš„æ—¶é—´ä¿¡æ¯
        start_times = [order['planned_start'] for order in processed_orders if order.get('planned_start')]
        end_times = [order['planned_end'] for order in processed_orders if order.get('planned_end')]
        
        if not start_times or not end_times:
            logger.warning(f"å·¥å•{work_order_nr}ç¼ºå°‘æ—¶é—´ä¿¡æ¯ï¼Œè·³è¿‡åŒæ­¥")
            return processed_orders
        
        # æŒ‰ç…§ç®—æ³•ç»†åˆ™æ‰§è¡ŒåŒæ­¥ç­–ç•¥
        sync_start, sync_end = self._calculate_sync_times(processed_orders, start_times, end_times)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è€ƒè™‘è½®ä¿æ—¶é—´
        maintenance_adjusted_start, maintenance_adjusted_end = self._adjust_for_maintenance(
            processed_orders, sync_start, sync_end
        )
        
        # ä½¿ç”¨è°ƒæ•´åçš„æ—¶é—´
        final_sync_start = maintenance_adjusted_start
        final_sync_end = maintenance_adjusted_end
        
        # ç”ŸæˆåŒæ­¥ç»„ID
        sync_group_id = f"SYNC_{orders[0].get('work_order_nr', '')}_{datetime.now().strftime('%Y%m%d%H%M%S')}"
        
        synchronized_orders = []
        
        # åº”ç”¨åŒæ­¥æ—¶é—´åˆ°æ‰€æœ‰æœºå°ï¼ˆæŒ‰ç…§æœºå°ç±»å‹åŒºåˆ«å¤„ç†ï¼‰
        for i, order in enumerate(processed_orders):
            sync_order = order.copy()
            
            original_start = order.get('planned_start')
            original_end = order.get('planned_end')
            
            # æ ¹æ®æœºå°ç±»å‹è®¾ç½®æ—¶é—´
            machine_code = order.get('maker_code') or order.get('feeder_code') or 'UNKNOWN'
            
            if order.get('work_order_type') == 'PACKING':
                # å·åŒ…æœºä½¿ç”¨è‡ªå·±æ ¡æ­£åçš„æ—¶é—´ï¼ˆä¿æŒæ—¶é—´æ ¡æ­£ç®—æ³•çš„ç»“æœï¼‰
                sync_order['planned_start'] = original_start or final_sync_start
                sync_order['planned_end'] = original_end or final_sync_end
                
                logger.info(f"   ğŸ¯ å·åŒ…æœº{machine_code}: ä¿æŒæ ¡æ­£åæ—¶é—´ {original_start} -> {original_end}")
                if original_end:
                    duration = (original_end - original_start).total_seconds() / 3600 if original_start else 0
                    logger.info(f"      â±ï¸ ç”Ÿäº§æ—¶é•¿: {duration:.1f}å°æ—¶")
            else:
                # å–‚ä¸æœºä¿æŒè‡ªå·±çš„æ—¶é—´ï¼Œä½†ç¡®ä¿åœ¨å·åŒ…æœºä¹‹å‰å®Œæˆ
                if original_end and original_end > final_sync_start:
                    # å¦‚æœå–‚ä¸æœºç»“æŸæ—¶é—´æ™šäºå·åŒ…æœºå¼€å§‹æ—¶é—´ï¼Œéœ€è¦è°ƒæ•´
                    sync_order['planned_start'] = original_start or final_sync_start
                    sync_order['planned_end'] = original_end or final_sync_end
                    logger.info(f"   ğŸƒ å–‚ä¸æœº{machine_code}: æ—¶é—´å†²çªï¼Œä¿æŒåŸæ—¶é—´")
                else:
                    # å–‚ä¸æœºæ—¶é—´åˆç†ï¼Œä¿æŒä¸å˜
                    sync_order['planned_start'] = original_start or final_sync_start
                    sync_order['planned_end'] = original_end or final_sync_end
                    logger.info(f"   ğŸƒ å–‚ä¸æœº{machine_code}: æ—¶é—´åˆç†ï¼Œä¿æŒåŸæ—¶é—´")
            
            # æ ‡è®°åŒæ­¥ä¿¡æ¯
            sync_order['is_synchronized'] = True
            sync_order['sync_group_id'] = sync_group_id
            sync_order['sync_sequence'] = i + 1
            sync_order['total_sync_machines'] = len(processed_orders)
            sync_order['original_start'] = original_start
            sync_order['original_end'] = original_end
            sync_order['sync_adjustment'] = {
                'start_adjustment_hours': (final_sync_start - original_start).total_seconds() / 3600 if original_start else 0,
                'end_adjustment_hours': (final_sync_end - original_end).total_seconds() / 3600 if original_end else 0
            }
            
            synchronized_orders.append(sync_order)
            
            # è¯¦ç»†æ—¥å¿—
            machine_code = sync_order.get('maker_code') or sync_order.get('feeder_code') or 'UNKNOWN'
            logger.info(f"   ğŸ“± æœºå°{machine_code}: {original_start.strftime('%Y-%m-%d %H:%M') if original_start else 'N/A'} -> {final_sync_start.strftime('%Y-%m-%d %H:%M')}")
        
        logger.info(f"âœ… å·¥å•{work_order_nr}åŒæ­¥å®Œæˆ")
        logger.info(f"   ğŸ“… ç»Ÿä¸€æ—¶é—´: {final_sync_start.strftime('%Y-%m-%d %H:%M')} - {final_sync_end.strftime('%Y-%m-%d %H:%M')}")
        logger.info(f"   ğŸ”§ åŒæ­¥ç»„ID: {sync_group_id}")
        
        return synchronized_orders
    
    def _calculate_sync_times(self, orders: List[Dict[str, Any]], start_times: List[datetime], end_times: List[datetime]) -> tuple:
        """
        è®¡ç®—åŒæ­¥æ—¶é—´ - æŒ‰ç…§ç®—æ³•ç»†åˆ™ç­–ç•¥
        
        ç®—æ³•ç»†åˆ™ç­–ç•¥ï¼š
        - å¼€å§‹æ—¶é—´ï¼šè€ƒè™‘æœ€æ™šå¼€å§‹æ—¶é—´ï¼ˆç¡®ä¿æ‰€æœ‰å‰ç½®æ¡ä»¶æ»¡è¶³ï¼‰
        - ç»“æŸæ—¶é—´ï¼šè€ƒè™‘æœ€æ™šç»“æŸæ—¶é—´ï¼ˆç¡®ä¿æ‰€æœ‰å·¥ä½œå®Œæˆï¼‰
        - ç‰¹æ®Šæƒ…å†µï¼šæŸäº›æœºå°åœ¨è½®ä¿æœŸé—´å¯ä»¥æœ‰ä¸åŒçš„å¤„ç†
        
        Args:
            orders: å·¥å•åˆ—è¡¨
            start_times: å¼€å§‹æ—¶é—´åˆ—è¡¨  
            end_times: ç»“æŸæ—¶é—´åˆ—è¡¨
            
        Returns:
            tuple: (åŒæ­¥å¼€å§‹æ—¶é—´, åŒæ­¥ç»“æŸæ—¶é—´)
        """
        # åŸºç¡€ç­–ç•¥ï¼šæŒ‰ç…§ä¸šåŠ¡é€»è¾‘è®¡ç®—æ—¶é—´
        # å·åŒ…æœºå†³å®šå·¥å•çš„æœ€ç»ˆæ—¶é—´ï¼Œå–‚ä¸æœºéœ€è¦æå‰å®Œæˆ
        packing_orders = [order for order in orders if order.get('work_order_type') == 'PACKING']
        feeding_orders = [order for order in orders if order.get('work_order_type') == 'FEEDING']
        
        if packing_orders:
            # ä½¿ç”¨å·åŒ…æœºçš„æ—¶é—´ä½œä¸ºä¸»è¦æ—¶é—´
            packing_starts = [order['planned_start'] for order in packing_orders if order.get('planned_start')]
            packing_ends = [order['planned_end'] for order in packing_orders if order.get('planned_end')]
            
            if packing_starts and packing_ends:
                sync_start = min(packing_starts)  # æœ€æ—©çš„å·åŒ…æœºå¼€å§‹æ—¶é—´
                sync_end = max(packing_ends)      # æœ€æ™šçš„å·åŒ…æœºç»“æŸæ—¶é—´
            else:
                sync_start = max(start_times)  # å…œåº•ç­–ç•¥
                sync_end = max(end_times)
        else:
            # å…œåº•ç­–ç•¥ï¼šæ²¡æœ‰å·åŒ…æœºå·¥å•æ—¶ä½¿ç”¨æœ€æ™šæ—¶é—´
            sync_start = max(start_times)  # æœ€æ™šå¼€å§‹æ—¶é—´
            sync_end = max(end_times)      # æœ€æ™šç»“æŸæ—¶é—´
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´è°ƒæ•´è®°å½•ï¼ˆæ¥è‡ªå‰é¢çš„å†²çªè§£å†³ï¼‰
        has_adjustment = any(order.get('schedule_adjusted') for order in orders)
        
        if has_adjustment:
            # å¦‚æœæœ‰è°ƒæ•´ï¼Œéœ€è¦é‡æ–°è®¡ç®—ä»¥ç¡®ä¿ä¸€è‡´æ€§
            logger.info(f"   âš ï¸  æ£€æµ‹åˆ°æ—¶é—´è°ƒæ•´ï¼Œé‡æ–°è®¡ç®—åŒæ­¥æ—¶é—´")
            
            # æ‰¾åˆ°è°ƒæ•´åçš„æœ€æ™šæ—¶é—´
            adjusted_starts = []
            adjusted_ends = []
            
            for order in orders:
                if order.get('schedule_adjusted'):
                    adjusted_starts.append(order['planned_start'])
                    adjusted_ends.append(order['planned_end'])
                else:
                    adjusted_starts.append(order['planned_start'])
                    adjusted_ends.append(order['planned_end'])
            
            sync_start = max(adjusted_starts)
            sync_end = max(adjusted_ends)
        
        return sync_start, sync_end
    
    def _adjust_for_maintenance(self, orders: List[Dict[str, Any]], sync_start: datetime, sync_end: datetime) -> tuple:
        """
        è€ƒè™‘æœºå°è½®ä¿æ—¶é—´çš„è°ƒæ•´
        
        ç®—æ³•ç»†åˆ™ä¸­æåˆ°ï¼šå·åŒ…æœº1å¯¹å·åŒ…æœº2ç»“æŸé˜¶æ®µä¸ºè½®ä¿
        å¯ä»¥è®¤ä¸º3ä¸ªå·åŒ…æœºå°çš„å¼€å§‹æ—¶é—´ä¸ºå·åŒ…æœº3çš„å¼€å§‹æ—¶é—´
        
        Args:
            orders: å·¥å•åˆ—è¡¨
            sync_start: åŸºç¡€åŒæ­¥å¼€å§‹æ—¶é—´
            sync_end: åŸºç¡€åŒæ­¥ç»“æŸæ—¶é—´
            
        Returns:
            tuple: (è°ƒæ•´åå¼€å§‹æ—¶é—´, è°ƒæ•´åç»“æŸæ—¶é—´)
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰å·åŒ…æœºåœ¨è½®ä¿ä¸­
        maintenance_machines = []
        
        for order in orders:
            machine_code = order.get('maker_code') or order.get('feeder_code')
            work_order_type = order.get('work_order_type', '')
            
            # ç®€å•çš„è½®ä¿æ£€æŸ¥é€»è¾‘ï¼ˆå®é™…åº”è¯¥æŸ¥è¯¢ aps_maintenance_plan è¡¨ï¼‰
            if work_order_type == 'PACKING' and machine_code:
                # å‡è®¾éƒ¨åˆ†æœºå°å¯èƒ½åœ¨è½®ä¿ä¸­
                maintenance_machines.append(machine_code)
        
        if maintenance_machines:
            logger.info(f"   ğŸ”§ æ£€æµ‹åˆ°å¯èƒ½çš„è½®ä¿æœºå°: {', '.join(maintenance_machines)}")
            
            # è½®ä¿è°ƒæ•´ç­–ç•¥ï¼š
            # å¦‚æœæœ‰æœºå°åœ¨è½®ä¿ï¼Œå¼€å§‹æ—¶é—´å¯èƒ½éœ€è¦å»¶å
            # è¿™é‡Œä½¿ç”¨ç®€åŒ–é€»è¾‘ï¼Œå®é™…åº”è¯¥æŸ¥è¯¢è½®ä¿è®¡åˆ’è¡¨
            
        # å½“å‰è¿”å›åŸå§‹æ—¶é—´ï¼ˆåç»­å¯ä»¥ä»æ•°æ®åº“æŸ¥è¯¢è½®ä¿è®¡åˆ’è¿›è¡Œæ›´ç²¾ç¡®è°ƒæ•´ï¼‰
        return sync_start, sync_end
    
    async def process_with_real_data(self, input_data: List[Dict[str, Any]], **kwargs) -> AlgorithmResult:
        """
        ä½¿ç”¨çœŸå®æ•°æ®åº“æ•°æ®æ‰§è¡Œå¹¶è¡Œå¤„ç†ï¼ˆç®€åŒ–ç‰ˆï¼‰
        
        Args:
            input_data: æ—¶é—´æ ¡æ­£åçš„å·¥å•æ•°æ®
            
        Returns:
            AlgorithmResult: å¹¶è¡Œå¤„ç†ç»“æœ
        """
        result = self.create_result()
        result.input_data = input_data
        result.metrics.processed_records = len(input_data)
        
        if not input_data:
            result.output_data = []
            return self.finalize_result(result)
        
        # æ ‡è®°ä½¿ç”¨äº†çœŸå®æ•°æ®åº“æ•°æ®
        result.metrics.custom_metrics = {
            'used_real_database_data': True
        }
        
        # ä½¿ç”¨ç›¸åŒçš„ç®€åŒ–é€»è¾‘
        work_order_groups = self._group_by_work_order(input_data)
        
        synchronized_orders = []
        sync_groups_count = 0
        
        for work_order_nr, orders in work_order_groups.items():
            if len(orders) > 1:
                sync_group = self._synchronize_machines(orders)
                synchronized_orders.extend(sync_group)
                sync_groups_count += 1
                logger.info(f"åŒæ­¥å·¥å•{work_order_nr}çš„{len(orders)}å°æœºå°(çœŸå®æ•°æ®)")
            else:
                order = orders[0].copy()
                order['is_synchronized'] = False
                order['sync_reason'] = 'å•å°æœºå°ï¼Œæ— éœ€åŒæ­¥'
                synchronized_orders.append(order)
        
        result.output_data = synchronized_orders
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        result.metrics.custom_metrics.update({
            'sync_groups_created': sync_groups_count,
            'total_machines_synchronized': sum(len(orders) for orders in work_order_groups.values() if len(orders) > 1),
            'sync_efficiency': sync_groups_count / len(work_order_groups) if work_order_groups else 0
        })
        
        logger.info(f"å¹¶è¡Œå¤„ç†å®Œæˆ(çœŸå®æ•°æ®): åˆ›å»º{sync_groups_count}ä¸ªåŒæ­¥ç»„ï¼Œå¤„ç†{len(synchronized_orders)}ä¸ªå·¥å•")
        return self.finalize_result(result)


def create_parallel_processing() -> ParallelProcessing:
    """
    åˆ›å»ºå¹¶è¡Œå¤„ç†ç®—æ³•å®ä¾‹
    
    Returns:
        ParallelProcessing: å¹¶è¡Œå¤„ç†ç®—æ³•å®ä¾‹
    """
    return ParallelProcessing()


def process_parallel_execution(work_orders: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    å¿«é€Ÿå¹¶è¡Œæ‰§è¡Œå¤„ç†ï¼ˆç®€åŒ–ç‰ˆï¼‰
    
    Args:
        work_orders: å·¥å•åˆ—è¡¨
        
    Returns:
        List[Dict]: å¹¶è¡Œå¤„ç†åçš„å·¥å•åˆ—è¡¨
    """
    processor = create_parallel_processing()
    result = processor.process(work_orders)
    return result.output_data