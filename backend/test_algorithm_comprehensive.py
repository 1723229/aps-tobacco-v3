"""
APSç®—æ³•ç»¼åˆæµ‹è¯•éªŒè¯
éªŒè¯ç®—æ³•è®¾è®¡æ–‡æ¡£è¦æ±‚çš„å®Œæ•´å®ç°
"""
import asyncio
import sys
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.algorithms.pipeline import AlgorithmPipeline
from app.algorithms.data_preprocessing import DataPreprocessor
from app.algorithms.merge_algorithm import MergeAlgorithm
from app.algorithms.split_algorithm import SplitAlgorithm
from app.algorithms.time_correction import TimeCorrection
from app.algorithms.parallel_processing import ParallelProcessing
from app.algorithms.work_order_generation import WorkOrderGeneration


class AlgorithmTester:
    """ç®—æ³•ç»¼åˆæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.pipeline = AlgorithmPipeline()
        
    def create_test_data(self) -> List[Dict[str, Any]]:
        """åˆ›å»ºæµ‹è¯•æ•°æ®"""
        base_date = datetime.now().replace(hour=8, minute=0, second=0, microsecond=0)
        
        test_data = [
            {
                'id': 1,
                'import_batch_id': 'TEST_BATCH_20241201',
                'work_order_nr': 'TEST_001',
                'article_nr': 'PA',  # äº§å“ä»£ç 
                'package_type': '20æ”¯è£…ç¡¬ç›’',
                'specification': '84mm',
                'quantity_total': 1000000,  # 100ä¸‡æ”¯
                'final_quantity': 1000000,
                'production_unit': 'ä¸‡æ”¯',
                'maker_code': 'JJ#01',  # å·åŒ…æœºä»£ç 
                'feeder_code': 'WS#01',  # å–‚ä¸æœºä»£ç 
                'planned_start': base_date,
                'planned_end': base_date + timedelta(hours=8),
                'production_date_range': '12.01-12.01',
                'validation_status': 'VALID'
            },
            {
                'id': 2,
                'import_batch_id': 'TEST_BATCH_20241201',
                'work_order_nr': 'TEST_002',
                'article_nr': 'PA',  # åŒä¸€äº§å“
                'package_type': '20æ”¯è£…ç¡¬ç›’',
                'specification': '84mm',
                'quantity_total': 1500000,  # 150ä¸‡æ”¯
                'final_quantity': 1500000,
                'production_unit': 'ä¸‡æ”¯',
                'maker_code': 'JJ#02',  # ä¸åŒå·åŒ…æœº
                'feeder_code': 'WS#01',  # åŒä¸€å–‚ä¸æœº
                'planned_start': base_date + timedelta(hours=8),
                'planned_end': base_date + timedelta(hours=16),
                'production_date_range': '12.01-12.01',
                'validation_status': 'VALID'
            },
            {
                'id': 3,
                'import_batch_id': 'TEST_BATCH_20241201',
                'work_order_nr': 'TEST_003',
                'article_nr': 'PC',  # ä¸åŒäº§å“
                'package_type': '20æ”¯è£…ç¡¬ç›’',
                'specification': '84mm',
                'quantity_total': 800000,  # 80ä¸‡æ”¯
                'final_quantity': 800000,
                'production_unit': 'ä¸‡æ”¯',
                'maker_code': 'JJ#03',
                'feeder_code': 'WS#02',  # ä¸åŒå–‚ä¸æœº
                'planned_start': base_date,
                'planned_end': base_date + timedelta(hours=6),
                'production_date_range': '12.01-12.01',
                'validation_status': 'VALID'
            }
        ]
        
        return test_data
    
    def create_test_machine_relations(self) -> Dict[str, List[str]]:
        """åˆ›å»ºæµ‹è¯•æœºå°å…³ç³»æ•°æ®"""
        return {
            'WS#01': ['JJ#01', 'JJ#02'],  # å–‚ä¸æœºWS#01å¯¹åº”ä¸¤å°å·åŒ…æœº
            'WS#02': ['JJ#03'],           # å–‚ä¸æœºWS#02å¯¹åº”ä¸€å°å·åŒ…æœº
        }
    
    def create_test_machine_speeds(self) -> Dict[str, Dict[str, Any]]:
        """åˆ›å»ºæµ‹è¯•æœºå°é€Ÿåº¦æ•°æ®"""
        return {
            'JJ#01': {
                'article_nr': 'PA',
                'speed': 8000,  # 8000æ”¯/åˆ†é’Ÿ
                'efficiency_rate': 0.85
            },
            'JJ#02': {
                'article_nr': 'PA',
                'speed': 8500,  # 8500æ”¯/åˆ†é’Ÿ
                'efficiency_rate': 0.90
            },
            'JJ#03': {
                'article_nr': 'PC',
                'speed': 7500,  # 7500æ”¯/åˆ†é’Ÿ
                'efficiency_rate': 0.80
            }
        }
    
    def test_data_preprocessing(self) -> Dict[str, Any]:
        """æµ‹è¯•æ•°æ®é¢„å¤„ç†"""
        print("\n=== æµ‹è¯•æ•°æ®é¢„å¤„ç† ===")
        
        preprocessor = DataPreprocessor()
        test_data = self.create_test_data()
        
        result = preprocessor.process(test_data)
        
        # éªŒè¯ç»“æœ
        assert result.success, f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {result.error_summary}"
        assert len(result.output_data) == 3, f"é¢„æœŸ3æ¡æ•°æ®ï¼Œå®é™…{len(result.output_data)}æ¡"
        
        print(f"âœ… æ•°æ®é¢„å¤„ç†é€šè¿‡: è¾“å…¥{len(test_data)}æ¡ï¼Œè¾“å‡º{len(result.output_data)}æ¡")
        return {
            'stage': 'data_preprocessing',
            'success': True,
            'input_count': len(test_data),
            'output_count': len(result.output_data),
            'output_data': result.output_data
        }
    
    def test_merge_algorithm(self, input_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æµ‹è¯•è§„åˆ™åˆå¹¶ç®—æ³•"""
        print("\n=== æµ‹è¯•è§„åˆ™åˆå¹¶ç®—æ³• ===")
        
        merger = MergeAlgorithm()
        result = merger.process(input_data)
        
        # éªŒè¯ç»“æœ
        assert result.success, f"è§„åˆ™åˆå¹¶å¤±è´¥: {result.error_summary}"
        
        print(f"âœ… è§„åˆ™åˆå¹¶é€šè¿‡: è¾“å…¥{len(input_data)}æ¡ï¼Œè¾“å‡º{len(result.output_data)}æ¡")
        return {
            'stage': 'merge_algorithm',
            'success': True,
            'input_count': len(input_data),
            'output_count': len(result.output_data),
            'output_data': result.output_data
        }
    
    def test_split_algorithm(self, input_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æµ‹è¯•è§„åˆ™æ‹†åˆ†ç®—æ³•"""
        print("\n=== æµ‹è¯•è§„åˆ™æ‹†åˆ†ç®—æ³• ===")
        
        splitter = SplitAlgorithm()
        machine_relations = self.create_test_machine_relations()
        
        result = splitter.process(input_data, maker_mapping=machine_relations)
        
        # éªŒè¯ç»“æœ
        assert result.success, f"è§„åˆ™æ‹†åˆ†å¤±è´¥: {result.error_summary}"
        
        print(f"âœ… è§„åˆ™æ‹†åˆ†é€šè¿‡: è¾“å…¥{len(input_data)}æ¡ï¼Œè¾“å‡º{len(result.output_data)}æ¡")
        return {
            'stage': 'split_algorithm',
            'success': True,
            'input_count': len(input_data),
            'output_count': len(result.output_data),
            'output_data': result.output_data
        }
    
    def test_time_correction(self, input_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æµ‹è¯•æ—¶é—´æ ¡æ­£ç®—æ³•"""
        print("\n=== æµ‹è¯•æ—¶é—´æ ¡æ­£ç®—æ³• ===")
        
        time_corrector = TimeCorrection()
        result = time_corrector.process(input_data)
        
        # éªŒè¯ç»“æœ
        assert result.success, f"æ—¶é—´æ ¡æ­£å¤±è´¥: {result.error_summary}"
        
        print(f"âœ… æ—¶é—´æ ¡æ­£é€šè¿‡: è¾“å…¥{len(input_data)}æ¡ï¼Œè¾“å‡º{len(result.output_data)}æ¡")
        return {
            'stage': 'time_correction',
            'success': True,
            'input_count': len(input_data),
            'output_count': len(result.output_data),
            'output_data': result.output_data
        }
    
    def test_parallel_processing(self, input_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶è¡Œåˆ‡åˆ†ç®—æ³•"""
        print("\n=== æµ‹è¯•å¹¶è¡Œåˆ‡åˆ†ç®—æ³• ===")
        
        parallel_processor = ParallelProcessing()
        machine_relations = self.create_test_machine_relations()
        machine_speeds = self.create_test_machine_speeds()
        
        result = parallel_processor.process(
            input_data, 
            machine_relations=machine_relations,
            machine_speeds=machine_speeds
        )
        
        # éªŒè¯ç»“æœ
        assert result.success, f"å¹¶è¡Œåˆ‡åˆ†å¤±è´¥: {result.error_summary}"
        
        # æ£€æŸ¥å¹¶è¡Œç»„æ˜¯å¦æ­£ç¡®åˆ›å»º
        parallel_groups = {}
        for order in result.output_data:
            group_id = order.get('parallel_group_id')
            if group_id:
                if group_id not in parallel_groups:
                    parallel_groups[group_id] = []
                parallel_groups[group_id].append(order)
        
        print(f"âœ… å¹¶è¡Œåˆ‡åˆ†é€šè¿‡: è¾“å…¥{len(input_data)}æ¡ï¼Œè¾“å‡º{len(result.output_data)}æ¡")
        print(f"   åˆ›å»º{len(parallel_groups)}ä¸ªå¹¶è¡Œç»„")
        
        return {
            'stage': 'parallel_processing',
            'success': True,
            'input_count': len(input_data),
            'output_count': len(result.output_data),
            'parallel_groups_count': len(parallel_groups),
            'output_data': result.output_data
        }
    
    def test_work_order_generation(self, input_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æµ‹è¯•å·¥å•ç”Ÿæˆç®—æ³•"""
        print("\n=== æµ‹è¯•å·¥å•ç”Ÿæˆç®—æ³• ===")
        
        work_order_generator = WorkOrderGeneration()
        result = work_order_generator.process(input_data)
        
        # éªŒè¯ç»“æœ
        assert result.success, f"å·¥å•ç”Ÿæˆå¤±è´¥: {result.error_summary}"
        
        # ç»Ÿè®¡å·¥å•ç±»å‹
        feeder_orders = [wo for wo in result.output_data if wo.get('work_order_type') == 'HWS']
        maker_orders = [wo for wo in result.output_data if wo.get('work_order_type') == 'HJB']
        
        print(f"âœ… å·¥å•ç”Ÿæˆé€šè¿‡: è¾“å…¥{len(input_data)}æ¡ï¼Œè¾“å‡º{len(result.output_data)}æ¡")
        print(f"   å–‚ä¸æœºå·¥å•: {len(feeder_orders)}ä¸ª")
        print(f"   å·åŒ…æœºå·¥å•: {len(maker_orders)}ä¸ª")
        
        # éªŒè¯å…³é”®éœ€æ±‚ï¼šå–‚ä¸æœºå·¥å•æ•°é‡åº”è¯¥å°‘äºç­‰äºå·åŒ…æœºå·¥å•æ•°é‡
        assert len(feeder_orders) > 0, "å¿…é¡»ç”Ÿæˆå–‚ä¸æœºå·¥å•"
        assert len(maker_orders) > 0, "å¿…é¡»ç”Ÿæˆå·åŒ…æœºå·¥å•"
        assert len(feeder_orders) <= len(maker_orders), "å–‚ä¸æœºå·¥å•æ•°é‡åº”è¯¥ä¸å¤§äºå·åŒ…æœºå·¥å•æ•°é‡"
        
        return {
            'stage': 'work_order_generation',
            'success': True,
            'input_count': len(input_data),
            'output_count': len(result.output_data),
            'feeder_orders_count': len(feeder_orders),
            'maker_orders_count': len(maker_orders),
            'feeder_orders': feeder_orders,
            'maker_orders': maker_orders
        }
    
    async def test_full_pipeline(self) -> Dict[str, Any]:
        """æµ‹è¯•å®Œæ•´ç®¡é“"""
        print("\n=== æµ‹è¯•å®Œæ•´ç®—æ³•ç®¡é“ ===")
        
        test_data = self.create_test_data()
        
        # æ‰§è¡Œå®Œæ•´ç®¡é“ï¼ˆä¸ä½¿ç”¨æ•°æ®åº“ï¼‰
        result = await self.pipeline.execute_full_pipeline(test_data, use_real_data=False)
        
        # éªŒè¯ç»“æœ
        assert result['success'], f"å®Œæ•´ç®¡é“æ‰§è¡Œå¤±è´¥: {result.get('error', 'Unknown error')}"
        
        final_work_orders = result['final_work_orders']
        feeder_orders = [wo for wo in final_work_orders if wo.get('work_order_type') == 'HWS']
        maker_orders = [wo for wo in final_work_orders if wo.get('work_order_type') == 'HJB']
        
        print(f"âœ… å®Œæ•´ç®¡é“æµ‹è¯•é€šè¿‡!")
        print(f"   æ‰§è¡Œæ—¶é—´: {result['execution_duration_seconds']:.2f}ç§’")
        print(f"   è¾“å…¥è®°å½•: {result['summary']['input_records']}æ¡")
        print(f"   è¾“å‡ºå·¥å•: {result['summary']['output_work_orders']}æ¡")
        print(f"   å–‚ä¸æœºå·¥å•: {len(feeder_orders)}ä¸ª")
        print(f"   å·åŒ…æœºå·¥å•: {len(maker_orders)}ä¸ª")
        
        return result
    
    async def run_comprehensive_test(self):
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        print("ğŸ§ª å¼€å§‹APSç®—æ³•ç»¼åˆæµ‹è¯•éªŒè¯")
        print("=" * 60)
        
        try:
            # é€æ­¥æµ‹è¯•æ¯ä¸ªç®—æ³•é˜¶æ®µ
            test_results = []
            
            # 1. æ•°æ®é¢„å¤„ç†
            preprocessing_result = self.test_data_preprocessing()
            test_results.append(preprocessing_result)
            current_data = preprocessing_result['output_data']
            
            # 2. è§„åˆ™åˆå¹¶
            merge_result = self.test_merge_algorithm(current_data)
            test_results.append(merge_result)
            current_data = merge_result['output_data']
            
            # 3. è§„åˆ™æ‹†åˆ†
            split_result = self.test_split_algorithm(current_data)
            test_results.append(split_result)
            current_data = split_result['output_data']
            
            # 4. æ—¶é—´æ ¡æ­£
            time_result = self.test_time_correction(current_data)
            test_results.append(time_result)
            current_data = time_result['output_data']
            
            # 5. å¹¶è¡Œåˆ‡åˆ†
            parallel_result = self.test_parallel_processing(current_data)
            test_results.append(parallel_result)
            current_data = parallel_result['output_data']
            
            # 6. å·¥å•ç”Ÿæˆ
            work_order_result = self.test_work_order_generation(current_data)
            test_results.append(work_order_result)
            
            # 7. å®Œæ•´ç®¡é“æµ‹è¯•
            pipeline_result = await self.test_full_pipeline()
            
            print("\n" + "=" * 60)
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç®—æ³•å®ç°ç¬¦åˆè®¾è®¡æ–‡æ¡£è¦æ±‚")
            print("\nğŸ“Š æµ‹è¯•æ‘˜è¦:")
            for result in test_results:
                print(f"   {result['stage']}: âœ… è¾“å…¥{result['input_count']} -> è¾“å‡º{result['output_count']}")
            
            print(f"\nğŸš€ å®Œæ•´ç®¡é“æµ‹è¯•: âœ…")
            print(f"   æœ€ç»ˆç”Ÿæˆå·¥å•: {len(pipeline_result['final_work_orders'])}ä¸ª")
            
            return True
            
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return False


async def main():
    """ä¸»å‡½æ•°"""
    tester = AlgorithmTester()
    success = await tester.run_comprehensive_test()
    
    if success:
        print("\nâœ… ç®—æ³•éªŒè¯å®Œæˆ - æ‰€æœ‰æµ‹è¯•é€šè¿‡")
        return 0
    else:
        print("\nâŒ ç®—æ³•éªŒè¯å¤±è´¥ - è¯·æ£€æŸ¥å®ç°")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    exit(exit_code)
